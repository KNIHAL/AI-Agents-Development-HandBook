# üß† Memory Node

The `Memory` node in Flowise gives your agents **short-term conversational memory** ‚Äî letting them remember previous messages, context, and state across turns.

Without memory, LLMs treat every input like a blank slate. Memory makes your agents feel *smarter*, more *context-aware*, and *human-like*.

---

## üìå Why Use Memory?

| Use Case                         | Why Memory Matters                        |
|----------------------------------|-------------------------------------------|
| Chatbots / Assistants            | Keeps track of what user said earlier     |
| Multi-turn Task Execution        | Allows multi-step follow-ups              |
| Conversation History Logging     | Needed for agents like `ConversationalAgent` |
| Email/Doc agents                 | Helps when querying multiple related files|

---

## üß± Memory Types in Flowise

Flowise supports different memory types depending on use case.

| Type                    | Description                                                   |
|-------------------------|---------------------------------------------------------------|
| **Buffer Memory**       | Stores recent messages (basic, works like chat history)       |
| **Summary Memory**      | Stores a compressed summary of previous messages              |
| **Buffer Window Memory**| Only stores the last N messages (limits token usage)          |
| **Combined Memory**     | Hybrid of summary + buffer                                    |
| **VectorStore Retriever Memory** | Retrieves relevant past messages using embeddings   |

> ‚úÖ Most common for agents = `Buffer Memory` or `Combined Memory`

---

## ‚öôÔ∏è Common Settings

| Setting              | Description                                      |
|----------------------|--------------------------------------------------|
| Memory Key           | Key under which memory is stored (default: `chat_history`) |
| K                    | Number of messages to remember (for window memory) |
| Return Messages      | Whether to return full message objects or just text |
| Input Key / Output Key | Optional ‚Äì advanced usage                       |

---

## üß† How Memory Works in Flowise

1. You connect a `Memory` node to your LLM or Agent
2. Flowise keeps a record of past messages (up to N steps)
3. On each new message, memory is passed back to the LLM
4. LLM sees the full context ‚Üí responds accordingly

---

## üîó Example Flow

> **Conversational FAQ Bot**

```text
[Chat Input]
   ‚Üì
[Memory Node (Buffer)]
   ‚Üì
[Prompt Template]
   ‚Üì
[Chat Model (GPT/Ollama)]
   ‚Üì
[Text Output]
```

---

### üß™ Tips for Good Memory Use
| Tip                               | Why It Helps                         |
| --------------------------------- | ------------------------------------ |
| Use summary memory for long chats | Saves tokens                         |
| Limit `K` in window memory        | Controls cost + performance          |
| Log memory to console in debug    | Helps track what‚Äôs being remembered  |
| Use `Combined Memory` for hybrid  | Best of both buffer + summary worlds |

---
### ‚ö†Ô∏è Things to Watch Out For
| Pitfall                    | Fix                                   |
| -------------------------- | ------------------------------------- |
| Model "forgets" past input | Increase `K` or use different memory  |
| Output feels repetitive    | Add memory filtering or summarization |
| Token cost gets high       | Use summary or buffer window memory   |

----

‚úÖ Summary
Memory = your agent's short-term brain.
Without it, even the best LLMs will behave like goldfish üê†.

```text
Use Memory when:
‚úÖ You‚Äôre building a chatbot
‚úÖ You want multi-turn logic
‚úÖ You want context-aware replies
```